---
title: "Econophysics-Outline"
author: "CMSE 201"
date: "April 11, 2016"
output: html_document
---

# Make Money Money (Make Money Money)

## Learning Goals

- Reason about distributions
- See an example of how phenomena emerge from simple behavioral rules
- [Flesh this out]

## Introduction

We're going to play a series of games with money. In each game, you'll be asked to 

1. Make predictions about what you think will happen
2. Play the game
3. Reconcile the outcome of the game with what you predicted

When it comes to predictions, we're not grading you on whether you're "right." What we care about is that you can justify why you think what will happen will happen. 

In later games you'll also be proposing new rules and trying to think about how they'll affect the system.

## First Game: In for a Penny

### Setup

Each person in the room is an agent. All agents start with exactly one penny (no more, no less). 

### The Goal

End up with the most money

### How to Play

We'll pick a time (say, 3 minutes). Once the clock starts, here are what you should do as an agent:

1. Find exactly one other agent so you can engage in a money trade.
2. Flip a coin (or play a quick round of rock, paper, scissors / odds & evens) to determine who pays whom.
3. The winner pays the loser one penny.
4. Find another agent and repeat this process as many times as you can until time runs out.

### Make a Prediction

When we start the game, say with 17 agents, here's what it could look like if we plotted how much money each agent had:

![A plot of the each agent having 1 cent at the start of In for a Penny](http://d.pr/i/1gAvq+)

1. What do you think will that graph look like after one round of the game?
	1. Why?
2. What do you think that graph will look like after many rounds of the game?
	1. Why?
	2. How much money do you expect to end up with?

### Play the Game

Put time on the clock, start with a penny, and play the game. 

### Reconcile your Prediction

As a class, we're going to have people report out so we can quickly get a table of agent IDs and how much money they had. 

1. How does the table/graph compare to what you expected?

## Variation 1: In for a Pound?

Propose a single rule change: instead of starting with 1 penny apiece, all agents start with N pennies, where the class votes on/discusses what N should be. So, we're introducing a few new potentia quantities to the game:

- `starting_money`: or how much money each agent starts with.
- `number_of_rounds`: for how long/how many chances will the agents have to trade?
- `number_of_agents`: how many individuals will be involved in the trading system

 This discussion should go hand-in-hand with these questions:

1. If `starting_money` is greater than 1 pennies per agent, will that change the outcome of the game compared to when it was just 1? 
	1. If so, how will it change and why?
	2. If not, why won't it change?
2. Do you suppose there's a relationship between `starting_money`, and `number_of_rounds`?
	1. What do you think happens if `starting_money` is much, much greater than the `number_of_rounds`---that is, if every agent starts with a ginormous amount of money but only plays a few rounds.
3. What about when we fiddle with the `number_of_agents`?
	1. What happens if it's just a handful of agents, where each agent has the same very large amount of `starting_money`, and they trade for a long time. So, in this scenario, 
		- `number_of_agents` is very small (say less than 10?)
		- `starting_money` is very big
		- `number_of_rounds` is very big
4. What else should we be paying attention to in this scenario?

## The path diverges

We're now going to add a new complication to the game. You can pick any one of the following, or propose one of your own. The catch is that whatever you pick, the whole class has to agree on and understand, because the next thing you'll do is play the game with that new rule/complication. 

Also, remember. Before we play with a new rule, we should take time to **predict** what we think will happen, because when we're done we're going to **reconcile** the results with our predictions and see whether they make sense.

### Possible rule changes:

- The SEC (Securities and Exchange Commission) is out to lunch: **A single trade can be more than a penny**. Agents must negotiate the trade amount before flipping the coin/rolling the die. The only catch is that you can't trade more than the maximum amount of money held by the poorer person. For example, Agents Bond (7 pennies) and Romanov (14 pennies) can only exchange up to 7 pennies in a single trade, because any more than that and Bond risks going into debt.
- Some people get robbed: Each agent starts with some number K of "robbery" tokens. Maybe start with one. In any given trade, the losing party can spend a robbery token to steal the money anyway. Once a token is spent, it can't be re-used.
- Get Rich or Try Dying: At any point in the game, and agent can choose to shuffle off the mortal coil and leave all of their money to their estate. Why would they do that? Because they fear losing their money to the market and they want to finish the game without risking losing any more money. Here's how it works:
	- Agent Bond decides that once he can get up to 20 pennies, his life is complete. After he gets his 20th penny, he takes a dangerous mission to go behind enemy lines in an undisclosed location. He is never heard from again. Because MI-6 liquidates Bond's accounts on his presumed death, the final amount of money Bond finishes the game with is frozen at however much money he had when he expired. 
- Leveling the Scales: Whenever two agents with differing amounts of money enter into a trade (Say Agent Bond has 7 pennies, and Agent Romanov has 14 pennies), the agent with less money gets a probability advantage. So, determining the trade moves from being a coin-flip problem to a die-roll problem, where the less well-off party gets a weight in their favor. (In the case of a six-sided die---or d6---an example might be that 1--4 are victory rolls for Bond, while only 5 and 6 mean that Romanov wins.)
- The Rich Get Richer: This is basically the opposite of Leveling the Scales. When two agents of unequal wealth enter into a trade, the wealthier agent has a better chance of winning. In this scenario, it's interesting to consider whether and how the value of the weighting factor speeds up the concentration of wealth into the hands of the few.
- The loaded die: One of the agents isn't playing with a fair random number generator, but no one else knows the identity of this mystery person. What would it take to try to root out who the rigged-game agent is (in terms of rounds played)? If we do make a guess at who it is, can we also try to infer the value of the load on their die? (That is, say we identify our culprit. Can we use data to back-calculate what the weighting was on the die they were using?)
- Social Safety Net: **Trades may randomly get "taxed" by an outside person, who takes money from the trade and redistributes it to agents who are broke**. 
	- Designate one person to be the tax collector. The tax collector is not an agent. Instead, the tax collector can walk up to any potential trade before it's happened. When it's time to determine who wins, the tax collector flips their own coin. If the tax collector's coin comes up winning (for them), they may "tax" the trade and take an amount from it between 1 and the total amount being traded. (For example, Agents Bond and Romanov have agreed to flip for a 7 coin trade. Bond wins, but the tax collector also wins their own coin toss. The tax collector taxes the trade and takes 4 pennies, leaving Bond winning only three pennies. (So, the outcome of the trade is that Romanov gives up 7 coins, the tax collector gets four coins, and Bond gets three coins). In this scenario, whenever someone goes broke, they can approach the tax collector for money. If the tax collector has any money, they must give it to the person requesting the money.



## Notes for Instructors

### We left out a rule on purpose

In the first game (In for a Penny), the instructions don't say what to do in a case where two agents try to enter into a trade and at least one of them is broke (has zero pennies). If the class doesn't notice that missing feature during the prediction stage, let the game play out. Re-raise the issue/question after the first round. Let the class come to a consensus about how to handle situations in which at least one trader is broke. Consider these as just a few of the possibilities that might handle that case:

- No Trade: If at least one party is broke, the trade cannot happen. Find a new pairing.
- Leave The Game: If at least one party is broke, that person has to physically get off the trading floor because only people with money are allowed to trade.
- Shot at Redemption: If at least one party is broke, the broke party can still enter into a trade. IF the broke party wins, they get the money. If the broke party loses the coin flip, no money is exchanged. (This solution is sort of kind to the broke parties, because it gives them a chance to earn money back).
- Keep Digging: Broke agents (agents with zero or less money) can enter into trades. But, if a broke agent loses the coin flip, the broke agent must give an "I owe you one penny" slip to the winning agent. This is an interesting one because it invites the class to think about what happens to the total money supply as the game evolves. 

### What concepts are we trying to work on here?

- Capturing the state of a system. How can we figure out what information we'll want to know at a given time, and what data structures we ought to use to capture that information? Especially if we're thinking ahead to things we might want to plot
- Visualizing a distribution. We initially start this with a plot of agent_id vs. amount of money, which is useful. But what ought to become clear is that a plot in which agent 16 ends up with all the money is identical to a plot in which agent 2 ends up with all the money, so it would be helpful if we had a visual way of making it easier to see when two different graphical outcomes actually represent the same underlying thing.
- Weighting a probability. It might seem simple, but it's actually subtle: how can we bias an otherwise 50/50 event and implement that bias both in our human-scale game and in a programmed game?
- Considering a system's long-run behavior. How do we discern between transient effects and what will ultimately "dominate"
- Threshold values: If we consider variations like "Leveling the Scales," how would we try to determine the proper amount of bias that we should introduce to give poorer parties a fair chance at not losing everything? What would it even mean/look like if we had a system that was fair and didn't concentrate wealth?

### Why all these rule variations?

They give the students a chance to negotiate the game's evolution. They also set the groundwork for a discussion later where students will be challenged to create implementations of at least 2 different rules the class as a whole has come up with.
